{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2Zm+zC7LMIjDi5e41TCEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish33scss/practice_randomstuff/blob/master/twitter_hashtag_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n6H3UYDUc3I",
        "outputId": "bda80374-e195-45bf-d310-cf3cf4dd95c3"
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVv9UVoUkU7"
      },
      "source": [
        "def printtweetdata(n, ith_tweet):\n",
        "    print()\n",
        "    print(f\"Tweet {n}:\")\n",
        "    print(f\"Username:{ith_tweet[0]}\")\n",
        "    print(f\"Description:{ith_tweet[1]}\")\n",
        "    print(f\"Location:{ith_tweet[2]}\")\n",
        "    print(f\"Following Count:{ith_tweet[3]}\")\n",
        "    print(f\"Follower Count:{ith_tweet[4]}\")\n",
        "    print(f\"Total Tweets:{ith_tweet[5]}\")\n",
        "    print(f\"Retweet Count:{ith_tweet[6]}\")\n",
        "    print(f\"Tweet Text:{ith_tweet[7]}\")\n",
        "    print(f\"Hashtags Used:{ith_tweet[8]}\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRxdDsTKUk0I"
      },
      "source": [
        "def scrape(words, date_since, numtweet):\n",
        "    \n",
        "    # Creating DataFrame using pandas\n",
        "    db = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
        "                            'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
        "    \n",
        "    # We are using .Cursor() to search through twitter for the required tweets.\n",
        "    # The number of tweets can be restricted using .items(number of tweets)\n",
        "    tweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n",
        "                        since=date_since, tweet_mode='extended').items(numtweet)\n",
        "    \n",
        "    # .Cursor() returns an iterable object. Each item in\n",
        "    # the iterator has various attributes that you can access to\n",
        "    # get information about each tweet\n",
        "    list_tweets = [tweet for tweet in tweets]\n",
        "    \n",
        "    # Counter to maintain Tweet Count\n",
        "    i = 1\n",
        "    \n",
        "    # we will iterate over each tweet in the list for extracting information about each tweet\n",
        "    for tweet in list_tweets:\n",
        "        username = tweet.user.screen_name\n",
        "        description = tweet.user.description\n",
        "        location = tweet.user.location\n",
        "        following = tweet.user.friends_count\n",
        "        followers = tweet.user.followers_count\n",
        "        totaltweets = tweet.user.statuses_count\n",
        "        retweetcount = tweet.retweet_count\n",
        "        hashtags = tweet.entities['hashtags']\n",
        "        \n",
        "        # Retweets can be distinguished by a retweeted_status attribute,\n",
        "        # in case it is an invalid reference, except block will be executed\n",
        "        try:\n",
        "            text = tweet.retweeted_status.full_text\n",
        "        except AttributeError:\n",
        "            text = tweet.full_text\n",
        "        hashtext = list()\n",
        "        for j in range(0, len(hashtags)):\n",
        "            hashtext.append(hashtags[j]['text'])\n",
        "        \n",
        "        # Here we are appending all the extracted information in the DataFrame\n",
        "        ith_tweet = [username, description, location, following,\n",
        "                    followers, totaltweets, retweetcount, text, hashtext]\n",
        "        db.loc[len(db)] = ith_tweet\n",
        "        \n",
        "        # Function call to print tweet data on screen\n",
        "        printtweetdata(i, ith_tweet)\n",
        "        i = i+1\n",
        "    filename = 'scraped_tweets.csv'\n",
        "    \n",
        "    # we will save our database as a CSV file.\n",
        "    db.to_csv(filename)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKxB7WQ4UotO",
        "outputId": "71313a1e-005c-46d1-9045-0db01335e7e9"
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    # Enter your own credentials obtained\n",
        "    # from your developer account\n",
        "    \n",
        "    ACCESS_TOKEN = \"1439545051558805509-tz31TWuPp8vETgshEeKmeH9WbIJJyJ\"\n",
        "    access_token_secret = \"D8FN3ZG1RyhWpqhrp8ouL4KgvBSzClopYisKOeAy2zzP3\"\n",
        "\n",
        "    api_key = \"t2tzTVcblqtsmusnOPpJt9xjq\"\n",
        "    api_key_secret = \"OgYRjbWdwZc2DlRnGzAzsBAJlVFo4Ma5gfk1VfKpZL2cQhsxSS\"\n",
        "    consumer_key = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
        "    consumer_secret = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
        "    access_key = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
        "    access_secret = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
        "    auth = tweepy.OAuthHandler(consumer_key= api_key, consumer_secret=api_key_secret)\n",
        "    auth.set_access_token(ACCESS_TOKEN,access_token_secret)\n",
        "    api = tweepy.API(auth)\n",
        "    \n",
        "    # Enter Hashtag and initial date\n",
        "    print(\"Enter Twitter HashTag to search for\")\n",
        "    words = input()\n",
        "    print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
        "    date_since = input()\n",
        "    \n",
        "    # number of tweets you want to extract in one run\n",
        "    numtweet = 100\n",
        "    scrape(words, date_since, numtweet)\n",
        "    print('Scraping has completed!')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Twitter HashTag to search for\n",
            "dalitlivematter\n",
            "Enter Date since The Tweets are required in yyyy-mm--dd\n",
            "2021-10-10\n",
            "\n",
            "Tweet 1:\n",
            "Username:SrishtiFightSma\n",
            "Description:Please save our only child, Srishti Rani from a rare & deadly disease, Spinal Muscular Atrophy (SMA) Type 1. need Zolgensma (16 Crores) earliest.\n",
            "Please help\n",
            "Location:\n",
            "Following Count:518\n",
            "Follower Count:124\n",
            "Total Tweets:1380\n",
            "Retweet Count:1\n",
            "Tweet Text:@SrishtFightSma @HemantSorenJMM @BhimArmyChief @Mayawati @DalitLiveMatter @dalitwomenfight @DalitRights \n",
            "Please save srishti \n",
            "She is in ICU from last 45 Days.\n",
            "Please helpüôè\n",
            "Hashtags Used:[]\n",
            "Scraping has completed!\n"
          ]
        }
      ]
    }
  ]
}